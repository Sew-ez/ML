{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmANPR2jhCR6"
      },
      "source": [
        "# Simple Object Detection in Tensorflow\n",
        "\n",
        "This lab will walk you through how to use object detection models available in [Tensorflow Hub](https://www.tensorflow.org/hub). In the following sections, you will:\n",
        "\n",
        "* explore the Tensorflow Hub for object detection models\n",
        "* load the models in your workspace\n",
        "* preprocess an image for inference\n",
        "* run inference on the models and inspect the output\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkMLuGDhCR6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (3.20.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_hub) (2.15.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow_hub) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow_hub\n",
        "%pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OEoRKdmByrb0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb8MBgTOhCR6"
      },
      "source": [
        "### Download the model from Tensorflow Hub\n",
        "\n",
        "Tensorflow Hub is a repository of trained machine learning models which you can reuse in your own projects.\n",
        "- You can see the domains covered [here](https://tfhub.dev/) and its subcategories.\n",
        "- For this lab, you will want to look at the [image object detection subcategory](https://tfhub.dev/s?module-type=image-object-detection).\n",
        "- You can select a model to see more information about it and copy the URL so you can download it to your workspace.\n",
        "- We selected a [inception resnet version 2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1)\n",
        "- You can also modify this following cell to choose the other model that we selected, [ssd mobilenet version 2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C9pCzz4uy20U"
      },
      "outputs": [],
      "source": [
        "# you can switch the commented lines here to pick the other model\n",
        "\n",
        "# inception resnet version 2\n",
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "\n",
        "# You can choose ssd mobilenet version 2 instead and compare the results\n",
        "#module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3trj5FbhCR6"
      },
      "source": [
        "#### Load the model\n",
        "\n",
        "Next, you'll load the model specified by the `module_handle`.\n",
        "- This will take a few minutes to load the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0WHkGDHfhCR6"
      },
      "outputs": [],
      "source": [
        "model = hub.load(module_handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ey0FpHGhCR6"
      },
      "source": [
        "#### Choose the default signature\n",
        "\n",
        "Some models in the Tensorflow hub can be used for different tasks. So each model's documentation should show what *signature* to use when running the model.\n",
        "- If you want to see if a model has more than one signature then you can do something like `print(hub.load(module_handle).signatures.keys())`. In your case, the models you will be using only have the `default` signature so you don't have to worry about other types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X1BU7AGthCR6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KeysView(_SignatureMap({'default': <ConcreteFunction () -> Dict[['detection_class_names', TensorSpec(shape=(None, 1), dtype=tf.string, name=None)], ['detection_class_entities', TensorSpec(shape=(None, 1), dtype=tf.string, name=None)], ['detection_class_labels', TensorSpec(shape=(None, 1), dtype=tf.int64, name=None)], ['detection_scores', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)], ['detection_boxes', TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)]] at 0x7FC6E36429B0>}))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# take a look at the available signatures for this particular model\n",
        "model.signatures.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfc9ax9hhCR6"
      },
      "source": [
        "Please choose the 'default' signature for your object detector.\n",
        "- For object detection models, its 'default' signature will accept a batch of image tensors and output a dictionary describing the objects detected, which is what you'll want here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pzwR5zE_hCR7"
      },
      "outputs": [],
      "source": [
        "detector = model.signatures['default']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvb-3r3thCR7"
      },
      "source": [
        "### download_and_resize_image\n",
        "\n",
        "This function downloads an image specified by a given \"url\", pre-processes it, and then saves it to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ucsxak_qhCR7"
      },
      "outputs": [],
      "source": [
        "def download_and_resize_image(url, new_width=256, new_height=256):\n",
        "    '''\n",
        "    Fetches an image online, resizes it and saves it locally.\n",
        "\n",
        "    Args:\n",
        "        url (string) -- link to the image\n",
        "        new_width (int) -- size in pixels used for resizing the width of the image\n",
        "        new_height (int) -- size in pixels used for resizing the length of the image\n",
        "\n",
        "    Returns:\n",
        "        (string) -- path to the saved image\n",
        "    '''\n",
        "\n",
        "\n",
        "    # create a temporary file ending with \".jpg\"\n",
        "    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "\n",
        "    # opens the given URL\n",
        "    response = urlopen(url)\n",
        "\n",
        "    # reads the image fetched from the URL\n",
        "    image_data = response.read()\n",
        "\n",
        "    # puts the image data in memory buffer\n",
        "    image_data = BytesIO(image_data)\n",
        "\n",
        "    # opens the image\n",
        "    pil_image = Image.open(image_data)\n",
        "\n",
        "    # resizes the image. will crop if aspect ratio is different.\n",
        "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "\n",
        "    # converts to the RGB colorspace\n",
        "    pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "\n",
        "    # saves the image to the temporary file created earlier\n",
        "    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "\n",
        "    print(\"Image downloaded to %s.\" % filename)\n",
        "\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qodEJHhCR7"
      },
      "source": [
        "### Download and preprocess an image\n",
        "\n",
        "Now, using `download_and_resize_image` you can get a sample image online and save it locally.\n",
        "- We've provided a URL for you, but feel free to choose another image to run through the object detector.\n",
        "- You can use the original width and height of the image but feel free to modify it and see what results you get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xHTDalVrhCR7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image downloaded to /tmp/tmpf9xt71u7.jpg.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-4e9bff65542d>:31: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n"
          ]
        }
      ],
      "source": [
        "# You can choose a different URL that points to an image of your choice\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n",
        "\n",
        "# download the image and use the original height and width\n",
        "downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVNXUKMIhCR7"
      },
      "source": [
        "### run_detector\n",
        "\n",
        "This function will take in the object detection model `detector` and the path to a sample image, then use this model to detect objects and display its predicted class categories and detection boxes.\n",
        "- run_detector uses `load_image` to convert the image into a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wkkiQzKlhCR7"
      },
      "outputs": [],
      "source": [
        "def load_img(path):\n",
        "    '''\n",
        "    Loads a JPEG image and converts it to a tensor.\n",
        "\n",
        "    Args:\n",
        "        path (string) -- path to a locally saved JPEG image\n",
        "\n",
        "    Returns:\n",
        "        (tensor) -- an image tensor\n",
        "    '''\n",
        "\n",
        "    # read the file\n",
        "    img = tf.io.read_file(path)\n",
        "\n",
        "    # convert to a tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def run_detector(detector, path):\n",
        "    '''\n",
        "    Runs inference on a local file using an object detection model.\n",
        "\n",
        "    Args:\n",
        "        detector (model) -- an object detection model loaded from TF Hub\n",
        "        path (string) -- path to an image saved locally\n",
        "    '''\n",
        "\n",
        "    # load an image tensor from a local file path\n",
        "    img = load_img(path)\n",
        "\n",
        "    # add a batch dimension in front of the tensor\n",
        "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "\n",
        "    # run inference using the model\n",
        "    result = detector(converted_img)\n",
        "\n",
        "    # save the results in a dictionary\n",
        "    result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "    # print results\n",
        "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "\n",
        "    print(result[\"detection_scores\"])\n",
        "    print(result[\"detection_class_entities\"])\n",
        "    print(result[\"detection_boxes\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSEeJSkxhCR7"
      },
      "source": [
        "### Run inference on the image\n",
        "\n",
        "You can run your detector by calling the `run_detector` function. This will print the number of objects found followed by three lists:\n",
        "\n",
        "* The detection scores of each object found (i.e. how confident the model is),\n",
        "* The classes of each object found,\n",
        "* The bounding boxes of each object\n",
        "\n",
        "You will see how to overlay this information on the original image in the next sections and in this week's assignment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "csanHvDIz4_t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100 objects.\n",
            "[0.6544854  0.61145365 0.604227   0.5926324  0.59218603 0.5804905\n",
            " 0.55140555 0.49466994 0.47515708 0.47342214 0.4399594  0.41485175\n",
            " 0.4062968  0.3982887  0.3976522  0.3762098  0.37279382 0.36574802\n",
            " 0.3526071  0.33274597 0.30428725 0.2727656  0.26864928 0.2577708\n",
            " 0.25290608 0.24612123 0.23403853 0.20342894 0.18229364 0.18045738\n",
            " 0.1757127  0.16435127 0.15849987 0.15666083 0.15470858 0.15452757\n",
            " 0.14924906 0.13340649 0.12948243 0.12649675 0.12044211 0.11767349\n",
            " 0.11356074 0.11114738 0.11100248 0.10914914 0.10604038 0.08940525\n",
            " 0.08598239 0.08280209 0.08104528 0.0780609  0.0776035  0.07628627\n",
            " 0.07546879 0.07444175 0.07427193 0.07204817 0.07177558 0.07102216\n",
            " 0.07032688 0.06809705 0.06304505 0.0628592  0.06270938 0.06223935\n",
            " 0.05882129 0.0581505  0.05795779 0.05787582 0.05462391 0.05274323\n",
            " 0.05133709 0.04826554 0.0470842  0.04682961 0.04495212 0.0440514\n",
            " 0.04360704 0.04113467 0.04109954 0.03968571 0.03934991 0.03912783\n",
            " 0.03879521 0.03878605 0.03739635 0.03606932 0.0336711  0.0336685\n",
            " 0.03260201 0.03253517 0.03201493 0.02983094 0.02877989 0.02867636\n",
            " 0.02803965 0.02783178 0.0273437  0.02668238]\n",
            "[b'Person' b'Person' b'Person' b'Person' b'Footwear' b'Person' b'Building'\n",
            " b'Bicycle' b'Building' b'Window' b'Person' b'Bicycle' b'Wheel'\n",
            " b'Building' b'Building' b'Building' b'Person' b'Wheel' b'Window'\n",
            " b'Window' b'Building' b'Person' b'Van' b'Person' b'Bicycle wheel'\n",
            " b'Person' b'Window' b'Window' b'Building' b'Window' b'Window' b'Man'\n",
            " b'Person' b'Woman' b'Person' b'Clothing' b'Bicycle wheel' b'Window'\n",
            " b'Person' b'Window' b'Land vehicle' b'Land vehicle' b'Clothing' b'Window'\n",
            " b'Bicycle' b'Land vehicle' b'House' b'House' b'Man' b'Window' b'Clothing'\n",
            " b'Window' b'Footwear' b'Person' b'Man' b'Man' b'House' b'Building'\n",
            " b'Person' b'Clothing' b'Window' b'Person' b'Man' b'Person' b'Furniture'\n",
            " b'Jeans' b'Person' b'Person' b'Person' b'Land vehicle' b'Window' b'House'\n",
            " b'Woman' b'Man' b'Window' b'Person' b'Person' b'Clothing' b'Man' b'Man'\n",
            " b'Window' b'Car' b'Person' b'Man' b'Chair' b'Car' b'House' b'Window'\n",
            " b'Tire' b'Clothing' b'Window' b'Clothing' b'Land vehicle' b'Window'\n",
            " b'Window' b'Man' b'Van' b'Bus' b'Clothing' b'Car']\n",
            "[[5.12794435e-01 5.29271007e-01 6.01662338e-01 5.52094460e-01]\n",
            " [5.19745946e-01 6.01507068e-01 6.46124125e-01 6.34682953e-01]\n",
            " [5.05745947e-01 5.00440776e-01 6.01349175e-01 5.23089647e-01]\n",
            " [4.86308753e-01 4.12762254e-01 6.78550303e-01 4.59905565e-01]\n",
            " [8.15190852e-01 9.56118345e-01 8.42701733e-01 9.87144649e-01]\n",
            " [4.95466530e-01 9.23534274e-01 8.35634887e-01 9.99056876e-01]\n",
            " [1.10986074e-02 1.19120395e-02 7.39750385e-01 4.24907237e-01]\n",
            " [5.77825963e-01 3.66453230e-01 7.12805688e-01 4.83338207e-01]\n",
            " [7.74935409e-02 4.13054019e-01 5.79458833e-01 5.60309231e-01]\n",
            " [0.00000000e+00 1.19292580e-01 2.23897204e-01 1.83949068e-01]\n",
            " [5.14069736e-01 7.48097837e-01 5.91962218e-01 7.66569197e-01]\n",
            " [5.70777833e-01 3.61820370e-01 7.07328439e-01 4.29666817e-01]\n",
            " [6.32094145e-01 3.59869897e-01 7.03841686e-01 4.11815584e-01]\n",
            " [1.59085598e-02 6.84961617e-01 5.59388816e-01 8.11146796e-01]\n",
            " [0.00000000e+00 7.97109306e-01 6.73736036e-01 1.00000000e+00]\n",
            " [0.00000000e+00 2.17026919e-01 6.50973082e-01 4.32000875e-01]\n",
            " [5.00372708e-01 3.77004474e-01 6.33350551e-01 4.14514393e-01]\n",
            " [6.40339971e-01 4.45023417e-01 7.03034759e-01 4.83457506e-01]\n",
            " [1.94404612e-03 0.00000000e+00 1.39331967e-01 2.62884218e-02]\n",
            " [2.55186716e-03 9.66625452e-01 1.53752610e-01 1.00000000e+00]\n",
            " [1.41548156e-03 1.41050993e-03 7.64848351e-01 2.69351929e-01]\n",
            " [5.04901111e-01 3.60784888e-01 6.37663364e-01 3.85480136e-01]\n",
            " [4.83383805e-01 6.19484127e-01 5.62658012e-01 6.61572099e-01]\n",
            " [4.98201460e-01 3.64614099e-01 6.61157489e-01 4.04896408e-01]\n",
            " [6.31229341e-01 3.60322863e-01 7.04147041e-01 4.11499411e-01]\n",
            " [5.21806777e-01 5.77694833e-01 5.87613106e-01 6.00717783e-01]\n",
            " [2.19603732e-01 3.48738879e-01 3.38255525e-01 3.77067655e-01]\n",
            " [1.24826729e-01 2.50923932e-01 2.79914767e-01 2.81625867e-01]\n",
            " [2.57318467e-01 5.67493618e-01 5.30910075e-01 6.87876582e-01]\n",
            " [4.21753712e-02 8.74765277e-01 2.52863407e-01 9.13046181e-01]\n",
            " [1.56401619e-01 4.43365514e-01 2.22233787e-01 4.75784540e-01]\n",
            " [5.01994431e-01 9.21467483e-01 8.36361706e-01 1.00000000e+00]\n",
            " [5.23673594e-01 5.70347011e-01 5.84506154e-01 5.91607034e-01]\n",
            " [5.19169092e-01 5.99965990e-01 6.46330178e-01 6.34094715e-01]\n",
            " [5.13154805e-01 6.79228544e-01 5.50981283e-01 6.92548096e-01]\n",
            " [5.24344563e-01 9.24945474e-01 8.10528219e-01 9.97979462e-01]\n",
            " [6.38063252e-01 4.42797333e-01 7.01729059e-01 4.84131962e-01]\n",
            " [3.41055430e-02 3.55657607e-01 1.62304893e-01 3.74908745e-01]\n",
            " [4.88090277e-01 4.53366935e-01 6.22257173e-01 4.79664922e-01]\n",
            " [9.66504449e-04 3.07707369e-01 1.06515862e-01 3.32070321e-01]\n",
            " [4.82970089e-01 6.19791687e-01 5.64778984e-01 6.60652637e-01]\n",
            " [5.82391143e-01 3.64923388e-01 7.13891625e-01 4.84685332e-01]\n",
            " [5.23790002e-01 7.49292731e-01 5.85470319e-01 7.65311480e-01]\n",
            " [3.51464182e-01 9.74868834e-01 5.53043664e-01 9.98887122e-01]\n",
            " [6.09076977e-01 4.26833510e-01 7.05196321e-01 4.87107515e-01]\n",
            " [5.69254696e-01 3.59783024e-01 7.08566368e-01 4.28438723e-01]\n",
            " [0.00000000e+00 8.11187208e-01 6.93582773e-01 9.93253589e-01]\n",
            " [1.04295602e-02 2.29469892e-02 7.27312446e-01 4.22287554e-01]\n",
            " [4.84632313e-01 4.10697758e-01 6.94742799e-01 4.63139951e-01]\n",
            " [8.11544508e-02 3.84775937e-01 2.07952142e-01 4.11755383e-01]\n",
            " [5.38567245e-01 6.03585005e-01 6.34740770e-01 6.34476542e-01]\n",
            " [0.00000000e+00 1.24075906e-02 1.40296459e-01 2.47341208e-02]\n",
            " [6.29779935e-01 6.14883423e-01 6.44907892e-01 6.25335038e-01]\n",
            " [5.02842903e-01 3.82420689e-01 5.96016526e-01 4.12718803e-01]\n",
            " [5.14681399e-01 7.47871041e-01 5.91947734e-01 7.66782522e-01]\n",
            " [5.06433249e-01 5.00402689e-01 6.00717008e-01 5.23319662e-01]\n",
            " [0.00000000e+00 2.11128622e-01 6.50825799e-01 4.34384257e-01]\n",
            " [0.00000000e+00 7.06320822e-01 6.17161691e-01 8.65940571e-01]\n",
            " [4.89298165e-01 4.54274893e-01 5.72620332e-01 4.76397544e-01]\n",
            " [5.09207368e-01 4.16264892e-01 6.69016659e-01 4.59577173e-01]\n",
            " [4.67803981e-03 8.03107023e-01 1.59582257e-01 8.40365171e-01]\n",
            " [5.26175678e-01 5.68375826e-01 5.79436243e-01 5.82803071e-01]\n",
            " [5.02847612e-01 3.73985916e-01 6.47125959e-01 4.12972599e-01]\n",
            " [4.85917509e-01 4.44437206e-01 6.24690235e-01 4.73519802e-01]\n",
            " [5.74168622e-01 2.67251372e-01 6.57761574e-01 3.20314020e-01]\n",
            " [6.71982288e-01 9.40317750e-01 8.21177125e-01 9.89214003e-01]\n",
            " [5.24104774e-01 5.61555982e-01 5.78347027e-01 5.80502510e-01]\n",
            " [5.17589688e-01 7.57220507e-01 5.88313997e-01 7.71545768e-01]\n",
            " [5.23328543e-01 5.57813823e-01 5.79028904e-01 5.73553503e-01]\n",
            " [6.12360060e-01 4.27401572e-01 7.06096232e-01 4.88300264e-01]\n",
            " [0.00000000e+00 2.44237095e-01 6.08887486e-02 2.93773830e-01]\n",
            " [1.54844159e-02 1.94195344e-03 7.45163381e-01 2.59336472e-01]\n",
            " [4.93266404e-01 9.23959553e-01 8.36913288e-01 9.97706771e-01]\n",
            " [5.05292952e-01 3.60166430e-01 6.43362343e-01 3.91438514e-01]\n",
            " [8.43422767e-03 2.42121428e-01 4.97449562e-02 2.83145577e-01]\n",
            " [5.22109151e-01 5.36088049e-01 5.97674847e-01 5.53133190e-01]\n",
            " [5.13126016e-01 5.23810089e-01 6.00540400e-01 5.42965055e-01]\n",
            " [5.18315673e-01 5.03453434e-01 5.97545326e-01 5.22752881e-01]\n",
            " [5.20455718e-01 6.00931644e-01 6.45991087e-01 6.34363830e-01]\n",
            " [5.13168335e-01 6.79253876e-01 5.50486147e-01 6.92442954e-01]\n",
            " [4.29723203e-01 8.28743577e-01 5.90048730e-01 8.64375412e-01]\n",
            " [5.26593328e-01 6.27190769e-01 5.63289881e-01 6.53785050e-01]\n",
            " [5.04781127e-01 3.89410645e-01 6.15231216e-01 4.19951588e-01]\n",
            " [5.01324892e-01 3.64236265e-01 6.59752846e-01 4.03719962e-01]\n",
            " [5.73110282e-01 2.66732723e-01 6.66223586e-01 3.18649948e-01]\n",
            " [5.15103340e-01 6.24091804e-01 5.63832283e-01 6.58031821e-01]\n",
            " [8.32031518e-02 4.07567918e-01 5.84343970e-01 5.58310449e-01]\n",
            " [2.88201898e-01 4.62549098e-04 4.14279848e-01 3.67076844e-02]\n",
            " [6.27132773e-01 3.60995084e-01 7.05960691e-01 4.09780413e-01]\n",
            " [4.97159481e-01 4.55211073e-01 5.84271312e-01 4.77872074e-01]\n",
            " [1.17194243e-02 3.08072537e-01 9.73200500e-02 3.25075477e-01]\n",
            " [5.15893936e-01 3.80090386e-01 5.96972406e-01 4.11767155e-01]\n",
            " [5.12428999e-01 6.23649299e-01 5.62436640e-01 6.57682240e-01]\n",
            " [4.00773793e-01 8.84974301e-01 5.81656575e-01 9.39130187e-01]\n",
            " [0.00000000e+00 9.94759705e-03 1.36254013e-01 3.15974429e-02]\n",
            " [5.13905585e-01 5.29502392e-01 6.02055907e-01 5.52376091e-01]\n",
            " [5.10691524e-01 6.24039650e-01 5.63410044e-01 6.58179879e-01]\n",
            " [4.80379969e-01 6.20327830e-01 5.65284133e-01 6.60123467e-01]\n",
            " [5.38407385e-01 9.28024292e-01 7.13617265e-01 9.99452710e-01]\n",
            " [4.86337841e-01 6.20247364e-01 5.63528717e-01 6.60217762e-01]]\n"
          ]
        }
      ],
      "source": [
        "# runs the object detection model and prints information about the objects found\n",
        "run_detector(detector, downloaded_image_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
